# -*- coding: utf-8 -*-
"""Final draft for CIA 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hLFGNmwdR-6JyXFLCgEdr2bVpp93Znj0
"""

!pip install gradio

import tensorflow as tf
import cv2
import numpy as np
import gradio as gr

#importing model
def model(up_img):
  cnn = tf.keras.models.load_model("/content/digit_recognition_model (1).h5")

  #import image
  gray_image = cv2.cvtColor(up_img, cv2.COLOR_BGR2GRAY)

  #preprocess
  gray_image = np.expand_dims(gray_image, axis = -1)
  gray_image = gray_image.reshape((-1, 28, 28, 1))

  #predict
  prediction = cnn.predict(gray_image)

  #converting the float values to int values for y_test
  prediction = np.argmax(prediction, axis = 1)

  return "The prediction for your input is {}".format(int(prediction))

demo = gr.Interface(fn = model, inputs = 'image', outputs = 'text')
demo.launch()

"""**STREAMLIT**"""

!pip install streamlit

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import numpy as np
# from PIL import Image
# import tensorflow as tf
# 
# # Load your trained model
# model = tf.keras.models.load_model("/content/digit_recognition_model (1).h5")
# 
# 
# def main():
#     st.title("MNIST Handwritten Digits Streamlit Interface") #title of the Streamlit webpage
# 
#     # Allow users to upload their own image
#     uploaded_file = st.file_uploader("Upload Your Own Image", type=["jpg", "jpeg", "png"])
# 
#     if uploaded_file is not None: #uploaded file exists
#         # Display the uploaded image
#         uploaded_image = Image.open(uploaded_file)
#         st.image(uploaded_image, caption="Uploaded Image", use_column_width=True)
# 
#         #preprocess and pass the input to your model
#         #similar to Gradio
#         raw_image = np.array(uploaded_image)
#         reshaped_image = np.reshape(raw_image, (-1, 28, 28, 1))
#         prediction_raw = model.predict(reshaped_image)
#         predicted_label = np.argmax(prediction_raw)
# 
#         # Display the predicted label
#         st.write("Prediction:", predicted_label)
# 
# if __name__ == "__main__":
#     main()
#

!npm install -g localtunnel
!streamlit run /content/app.py &>/content/logs.txt &
!npx localtunnel --port 8501 & curl ipv4.icanhazip.com

"""**FLASK**"""

!pip install flask

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# from flask import Flask, render_template, request, jsonify
# import numpy as np
# from PIL import Image
# import base64
# import os
# from io import BytesIO
# from tensorflow.keras.models import load_model
# 
# app = Flask(__name__)
# 
# model = load_model('/content/mnist_mlp_model.h5')  # Replace with your model path
# 
# @app.route('/')
# def home():
#     return render_template('index.html')
# 
# @app.route('/predict', methods=['POST'])
# def predict():
#     # Get the image file from the request
#     image_file = request.files['file']
# 
#     # Process the image
#     img = Image.open(image_file).convert('L')  # Convert to grayscale
#     img = img.resize((28, 28))  # Resize to MNIST input size
#     img_array = np.array(img).reshape(1, 28*28, 1)  # Normalize
# 
#     # Make prediction
#     prediction = model.predict(img_array)
#     predicted_digit = np.argmax(prediction)
# 
#     # Convert the PIL Image to base64-encoded bytes
#     img_bytes = BytesIO()
#     img.save(img_bytes, format='PNG')
#     img_base64 = base64.b64encode(img_bytes.getvalue()).decode('utf-8')
# 
#     # Create a response with the base64-encoded image and prediction
#     response = {
#         'prediction': int(predicted_digit),
#         'image': {
#             'format': 'png',
#             'data': img_base64
#         }
#     }
# 
#     return jsonify(response)
# 
# if __name__ == '__main__':
#     app.run(debug=True)
#

!npm install localtunnel
!flask run &>/content/logs.txt &>/content/logs.txt &
!npx localtunnel --port 5000 & curl ipv4.icanhazip.com